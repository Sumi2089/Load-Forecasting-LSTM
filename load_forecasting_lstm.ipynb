{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d36b1a1-7ab6-4910-b818-7f247e1b6677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Import datasheet\n",
    "df = pd.read_csv('/home/sanda/Desktop/Thesis/Datasheet/csv file 6/train_dataframes.csv')\n",
    "df.head()\n",
    "\n",
    "df['Date Time'] = pd.to_datetime(df['datetime'], yearfirst=True)\n",
    "df['Year'] = df['Date Time'].dt.year\n",
    "df['Month'] = df['Date Time'].dt.month\n",
    "df['Day'] = df['Date Time'].dt.day\n",
    "df['Hour'] = df['Date Time'].dt.hour\n",
    "df['Minute'] = df['Date Time'].dt.minute\n",
    "df['Second'] = df['Date Time'].dt.second\n",
    "df.head()\n",
    "\n",
    "df['Demand'] = pd.to_numeric(df['DEMAND'], errors='coerce')\n",
    "\n",
    "df.drop(['datetime'], axis='columns', inplace=True, errors='ignore')\n",
    "df.drop(['week_X-2'], axis='columns', inplace=True, errors='ignore')\n",
    "df.drop(['week_X-3'], axis='columns', inplace=True, errors='ignore')\n",
    "df.drop(['week_X-4'], axis='columns', inplace=True, errors='ignore')\n",
    "df.drop(['MA_X-4'], axis='columns', inplace=True, errors='ignore')\n",
    "df.drop(['dayOfWeek'], axis='columns', inplace=True, errors='ignore')\n",
    "df.drop(['weekend'], axis='columns', inplace=True, errors='ignore')\n",
    "df.drop(['holiday'], axis='columns', inplace=True, errors='ignore')\n",
    "df.drop(['Holiday_ID'], axis='columns', inplace=True, errors='ignore')\n",
    "df.drop(['hourOfDay'], axis='columns', inplace=True, errors='ignore')\n",
    "df.drop(['T2M_toc'], axis='columns', inplace=True, errors='ignore')\n",
    "df.drop(['DEMAND'], axis='columns', inplace=True, errors='ignore')\n",
    "df.drop(['Date Time'], axis='columns', inplace=True, errors='ignore')\n",
    "df.drop(['Minute'], axis='columns', inplace=True, errors='ignore')\n",
    "df.drop(['Second'], axis='columns', inplace=True, errors='ignore')\n",
    "print(df.dtypes)\n",
    "df.head\n",
    "\n",
    "#Transform the Data\n",
    "#Into array\n",
    "X0 = []\n",
    "X1 = []\n",
    "X2 = []\n",
    "X3 = []\n",
    "X4 = []\n",
    "y = []\n",
    "\n",
    "#Append each of the values into this empty list\n",
    "for i in range(0, df.shape[0]-24):\n",
    "    X0.append(df.iloc[i:i+24, 0])\n",
    "    X1.append(df.iloc[i:i+24, 1])\n",
    "    X2.append(df.iloc[i:i+24, 2])\n",
    "    X3.append(df.iloc[i:i+24, 3])\n",
    "    X4.append(df.iloc[i:i+24, 4])\n",
    "    y.append(df.iloc[i+24, 4])\n",
    "\n",
    "X0, X1, X2, X3, X4, y = np.array(X0), np.array(X1), np.array(X2), np.array(X3), np.array(X4), np.array(y)\n",
    "y.shape\n",
    "\n",
    "y = np.reshape(y, (len(y),1))\n",
    "y.shape\n",
    "\n",
    "#Normalize the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X0 = scaler.fit_transform(X0) \n",
    "X1 = scaler.fit_transform(X1) \n",
    "X2 = scaler.fit_transform(X2) \n",
    "X3 = scaler.fit_transform(X3) \n",
    "X4 = scaler.fit_transform(X4) \n",
    "y = scaler.fit_transform(y) \n",
    "X4\n",
    "\n",
    "X = np.stack([X0, X1, X2, X3, X4], axis=2)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2a5c0f-1a0a-4b9b-909a-1c5214da08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the LSTM model\n",
    "X_train, X_test = X[ :-720], X[-720: ] \n",
    "y_train, y_test = y[ :-720], y[-720: ]\n",
    "X_train.shape[1], X_train.shape[2]\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "\n",
    "#Early stop the training if validation problem goes up\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "filepath = 'models/{epoch:02d}-{loss:.4f}-{val_loss:.4f}-{mae:.4f}-{val_mae:.4f}.hdf5'\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=20), ModelCheckpoint(filepath, monitor='loss', save_best_only=True, model='min')]\n",
    "\n",
    "#Training the model\n",
    "optimizers.SGD(momentum=0.9)\n",
    "model.compile(optimizer='SGD', loss='mse', metrics=['mae'])\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=5, callbacks=callbacks, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01c8f43-0ad2-4e7d-9822-431b59a71cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate and prediction\n",
    "MSE, MAE = model.evaluate(X_test, y_test)\n",
    "print(MSE, MAE)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "predictions\n",
    "\n",
    "#Plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.figure(figsize=(24,12))\n",
    "plt.title('1 hour ahead Electricity Demand Forecasting')\n",
    "plt.xlabel('Step(1 hour)', fontsize=14)\n",
    "plt.ylabel('Electricity Demand', fontsize=18)\n",
    "plt.plot(predictions)\n",
    "plt.plot(scaler.inverse_transform(y_test))\n",
    "plt.legend(['Forecast', 'Actual'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
